# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1op0H3Fk_hveDU9bq-pV6LWK2t75NQijM
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (Input, Resizing, Concatenate, GlobalAveragePooling2D, Dropout, Dense)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.regularizers import L1, L2
from sklearn.metrics import classification_report, confusion_matrix

# Load Dataset
dataset = np.load("/content/drive/MyDrive/Colab Notebooks/Inception V3 Dataset/pneumoniamnist.npz")

# Normalizing data
def normalize(images):
    return (images - np.min(images)) / (np.max(images) - np.min(images))

xtrain = normalize(dataset["train_images"].reshape(-1, 28, 28, 1))
ytrain = dataset["train_labels"]

xvalid = normalize(dataset["val_images"].reshape(-1, 28, 28, 1))
yvalid = dataset["val_labels"]

xtest = normalize(dataset["test_images"].reshape(-1, 28, 28, 1))
ytest = dataset["test_labels"]

# Class Distribution
def show_distribution(y, label):
    classes, counts = np.unique(y, return_counts=True)
    print(f"\n{label} Distribution:")
    for c, n in zip(classes, counts):
        print(f"Class {c}: {n} samples")
    return classes, counts

show_distribution(ytrain, "Train")
show_distribution(yvalid, "Validation")
show_distribution(ytest, "Test")

# Balancing class using data augmentation
datagen = ImageDataGenerator(
    rotation_range=5,
    width_shift_range=0.05,
    height_shift_range=0.05,
    zoom_range=0.05,
    brightness_range=[0.95, 1.05],
    horizontal_flip=True
)

# Geting the majority class count
unique_classes, class_counts = np.unique(ytrain, return_counts=True)
max_count = np.max(class_counts)

aug_images, aug_labels = [], []

# Looping through each class and augment to match the majority class
for cls in unique_classes:
    idx = np.where(ytrain == cls)[0]
    cls_images = xtrain[idx]
    cls_labels = ytrain[idx]
    needed = max_count - len(cls_images)

    if needed > 0:
        per_image = needed // len(cls_images) + 1
        for img, lbl in zip(cls_images, cls_labels):
            aug_iter = datagen.flow(img.reshape(1, *img.shape), lbl.reshape(1, 1), batch_size=1)
            for _ in range(per_image):
                new_img, new_lbl = next(aug_iter)
                aug_images.append(new_img[0])
                aug_labels.append(new_lbl[0])
                if len(aug_labels) >= needed:
                    break
            if len(aug_labels) >= needed:
                break

# Combining augmented data with original
xtrain_bal = np.concatenate([xtrain, np.array(aug_images)], axis=0)
ytrain_bal = np.concatenate([ytrain, np.array(aug_labels)], axis=0)

# Shuffling data
indices = np.arange(len(xtrain_bal))
np.random.shuffle(indices)
xtrain_bal = xtrain_bal[indices]
ytrain_bal = ytrain_bal[indices]

# Model Building using Transfer Learning (InceptionV3)

input_shape = (28, 28, 1)
resize_shape = (75, 75)

# Input Layer (1 channel grayscale)
input_layer = Input(shape=input_shape)

# Resize and convert grayscale to RGB (3 channels)
resized = Resizing(*resize_shape)(input_layer)
rgb_input = Concatenate()([resized, resized, resized])

# Load InceptionV3 without top layers
base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=rgb_input)

# Freeze most layers and unfreeze deeper ones
for layer in base_model.layers:
    layer.trainable = layer.name.startswith('conv3') or layer.name.startswith('conv4') or layer.name.startswith('conv5')

# Add custom classification head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu', kernel_regularizer=L2(1e-4), bias_regularizer=L1(1e-6))(x)
x = Dropout(0.5)(x)
output_layer = Dense(1, activation='sigmoid', kernel_regularizer=L2(1e-4), bias_regularizer=L1(1e-6))(x)

model = Model(inputs=input_layer, outputs=output_layer)
model.summary()

# Setting Custom Metrics

class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='f1_score', threshold=0.5, **kwargs):
        super().__init__(name=name, **kwargs)
        self.threshold = threshold
        self.tp = self.add_weight(name='tp', initializer='zeros')
        self.fp = self.add_weight(name='fp', initializer='zeros')
        self.fn = self.add_weight(name='fn', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.cast(y_pred > self.threshold, tf.float32)
        y_true = tf.cast(y_true, tf.float32)
        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))
        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))
        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))

    def result(self):
        precision = self.tp / (self.tp + self.fp + 1e-7)
        recall = self.tp / (self.tp + self.fn + 1e-7)
        return 2 * precision * recall / (precision + recall + 1e-7)

    def reset_states(self):
        self.tp.assign(0)
        self.fp.assign(0)
        self.fn.assign(0)

# Compiling Model

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=[
        "accuracy",
        tf.keras.metrics.AUC(name='auc'),
        F1Score(name='f1_score')
    ]
)

# Training Model

# Seting early stopping & model checkpoint
callbacks = [
    EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),
    ModelCheckpoint("best_model.weights.h5", save_best_only=True, save_weights_only=True)
]

history = model.fit(
    xtrain_bal, ytrain_bal,
    validation_data=(xvalid, yvalid),
    epochs=50,
    batch_size=32,
    callbacks=callbacks,
    verbose=1
)

# Evaluating the result

test_loss, test_acc, test_auc, test_f1 = model.evaluate(xtest, ytest, verbose=0)
print(f"\nTest Results:\nLoss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, AUC: {test_auc:.4f}, F1: {test_f1:.4f}")

# Visualization the data using appropriate metrices

def plot_training(history):
    plt.figure(figsize=(12, 8))

    metrics = ['loss', 'accuracy', 'auc', 'f1_score']
    for i, metric in enumerate(metrics):
        plt.subplot(2, 2, i+1)
        plt.plot(history.history[metric], label='Train')
        plt.plot(history.history[f'val_{metric}'], label='Validation')
        plt.title(metric.upper())
        plt.legend()

    plt.tight_layout()
    plt.show()

plot_training(history)